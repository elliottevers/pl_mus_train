{"version":3,"file":"predict.js","sourceRoot":"","sources":["../../src/algorithm/predict.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;AAGA,wCAAqC;AAErC,uCAAoC;AAEpC,oDAAqD;AAGrD,yCAAsC;AACtC,wCAAkC;AAElC,IAAM,CAAC,GAAG,OAAO,CAAC,YAAY,CAAC,CAAC;AAEhC,IAAiB,OAAO,CAyIvB;AAzID,WAAiB,OAAO;IAEpB,IAAO,QAAQ,GAAG,mBAAQ,CAAC,QAAQ,CAAC;IAEpC,IAAO,SAAS,GAAG,yBAAa,CAAC,SAAS,CAAC;IAG3C,IAAO,SAAS,GAAG,yBAAa,CAAC,SAAS,CAAC;IAC3C,IAAO,OAAO,GAAG,qBAAS,CAAC,OAAO,CAAC;IACnC,IAAO,MAAM,GAAG,YAAG,CAAC,MAAM,CAAC;IAC3B,IAAO,KAAK,GAAG,aAAK,CAAC,KAAK,CAAC;IAG3B;QAA6B,2BAAQ;QAArC;;QA2HA,CAAC;QAzHU,0BAAQ,GAAf;YACI,OAAO,OAAO,CAAA;QAClB,CAAC;QAED,mCAAiB,GAAjB,UAAkB,kBAAoC,EAAE,kBAA4C;YAEhG,IAAI,kBAAkB,CAAC,YAAY,KAAK,SAAS,EAAE;gBAE/C,kEAAkE;gBAClE,yBAAyB;gBACzB,KAAK;gBACL,EAAE;gBACF,qDAAqD;gBACrD,EAAE;gBACF,2CAA2C;gBAC3C,iCAAiC;gBACjC,+BAA+B;gBAC/B,yBAAyB;gBACzB,YAAY;gBACZ,SAAS;gBACT,IAAI;gBAEJ,MAAM,uDAAuD,CAAA;aAEhE;iBAAM,IAAI,kBAAkB,CAAC,YAAY,KAAK,SAAS,EAAE;gBAEtD,IAAI,aAAa,GAAuB,EAAE,CAAC;gBAE3C,kCAAkC;gBAElC,IAAI,gBAAgB,GAAG,UAAC,IAAI;oBACxB,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,UAAU,GAAC,CAAC,CAAC,CAAA;gBACnD,CAAC,CAAC;gBAEF,IAAI,eAAe,GAA6B,CAAC,CAAC,OAAO,CAAC,kBAAkB,EAAE,gBAAgB,CAAC,CAAC;gBAEhG,2CAA2C;gBAC3C,4CAA4C;gBAC5C,0DAA0D;gBAC1D,IAAI;gBAEJ,KAA0B,UAA4B,EAA5B,KAAA,MAAM,CAAC,IAAI,CAAC,eAAe,CAAC,EAA5B,cAA4B,EAA5B,IAA4B,EAAE;oBAAnD,IAAI,aAAa,SAAA;oBAClB,IAAI,SAAS,GAAG,eAAe,CAAC,aAAa,CAAC,CAAC;oBAC/C,aAAa,CAAC,IAAI,CAAC,CAAC,SAAS,CAAC,SAAS,CAAC,MAAM,GAAC,CAAC,CAAC,CAAC,CAAC,CAAA;iBACtD;gBAED,kCAAkC;gBAClC,kDAAkD;gBAClD,EAAE;gBACF,sBAAsB;gBAEtB,OAAO,aAAa,CAAA;aAEvB;iBAAM;gBACH,MAAM,CAAC,cAAc,EAAE,kBAAkB,CAAC,YAAY,EAAE,eAAe,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA;aACrF;QACL,CAAC;QAED,uCAAqB,GAArB,UAAsB,cAAc;YAChC,cAAc,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC;YACpC,OAAO,cAAc,CAAC;QAC1B,CAAC;QAED,uDAAuD;QACvD,mCAAiB,GAAjB,UACI,MAA2B,EAC3B,QAA2B,EAC3B,kBAA+C,EAC/C,YAAyB;YAEzB,OAAO,MAAM,CAAA;QACjB,CAAC;QAED,2DAA2D;QAC3D,mCAAiB,GAAjB,UACI,QAA2B,EAC3B,YAAyB,EACzB,gBAA6B,EAC7B,YAAyB;YAGzB,IAAI,cAAc,GAAG,YAAY,CAAC;YAElC,IAAI,MAAM,GAAG,IAAI,MAAM,CAAC,KAAK,CAAC,CAAC;YAE/B,KAAK,IAAI,SAAS,IAAI,QAAQ,EAAE;gBAE5B,6CAA6C;gBAE7C,IAAI,IAAI,GAAG,KAAK,CAAC,iBAAiB,CAC9B,YAAY,CAAC,SAAS,EAAE,EACxB,MAAM,CAAC,SAAS,CAAC,EACjB,YAAY,CAAC,SAAS,CAAC,SAAS,CACnC,CAAC;gBAEF,IAAI,yBAAyB,GAAG,cAAc,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC,SAAS,EAAE,CAAC;gBAEjF,yDAAyD;gBAEzD,sCAAsC;gBACtC,KAAiB,UAAyB,EAAzB,uDAAyB,EAAzB,uCAAyB,EAAzB,IAAyB,EAAE;oBAAvC,IAAI,MAAI,kCAAA;oBAET,IAAI,CAAC,iBAAiB,CAAC,aAAa,CAAC,CAAC;oBAEtC,IAAI,CAAC,YAAY,CACb,MAAI,CAAC,KAAK,CAAC,IAAI,CAAC,UAAU,EAC1B,CAAC,EACD,MAAI,CAAC,KAAK,CAAC,IAAI,CAAC,YAAY,EAAE,EAC9B,GAAG,CACN,CAAC;oBAEF,IAAI,UAAU,GAAG,MAAI,CAAC;oBAEtB,UAAU,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC;oBAEhC,IAAI,CAAC,SAAS,CACV,CAAC,UAAU,CAAC,CACf,CAAA;iBACJ;aACJ;QACL,CAAC;QACL,cAAC;IAAD,CAAC,AA3HD,CAA6B,QAAQ,GA2HpC;IA3HY,eAAO,UA2HnB,CAAA;AACL,CAAC,EAzIgB,OAAO,GAAP,eAAO,KAAP,eAAO,QAyIvB","sourcesContent":["import {note, note as n} from \"../note/note\";\nimport {window} from \"../render/window\";\nimport {segment} from \"../segment/segment\";\nimport {track} from \"../track/track\";\nimport {user_input} from \"../control/user_input\";\nimport {targeted} from \"./targeted\";\nimport {trainer} from \"../train/trainer\";\nimport {modes_texture} from \"../constants/constants\";\nimport {history} from \"../history/history\";\nimport TreeModel = require(\"tree-model\");\nimport {trainable} from \"./trainable\";\nimport {log} from \"../log/logger\";\nimport {message} from \"../message/messenger\";\nconst _ = require('underscore');\n\nexport namespace predict {\n    import UserInputHandler = user_input.UserInputHandler;\n    import Targeted = targeted.Targeted;\n    import StructTrain = trainer.StructTrain;\n    import POLYPHONY = modes_texture.POLYPHONY;\n    import Note = note.Note;\n    import TypeSequenceTarget = history.TypeSequenceTarget;\n    import MONOPHONY = modes_texture.MONOPHONY;\n    import PREDICT = trainable.PREDICT;\n    import Logger = log.Logger;\n    import Track = track.Track;\n    import Messenger = message.Messenger;\n\n    export class Predict extends Targeted {\n\n        public get_name(): string {\n            return PREDICT\n        }\n\n        determine_targets(user_input_handler: UserInputHandler, notes_segment_next: TreeModel.Node<n.Note>[]): TypeSequenceTarget {\n\n            if (user_input_handler.mode_texture === POLYPHONY) {\n\n                // let chords_grouped: TreeModel.Node<n.Note>[][] = Harmony.group(\n                //     notes_segment_next\n                // );\n                //\n                // let chords_monophonified: TypeSequenceTarget = [];\n                //\n                // for (let note_group of chords_grouped) {\n                //     chords_monophonified.push(\n                //         Harmony.monophonify(\n                //             note_group\n                //         )\n                //     );\n                // }\n\n                throw 'polyphonic targets for prediction not yet implemented'\n\n            } else if (user_input_handler.mode_texture === MONOPHONY) {\n\n                let notes_grouped: TypeSequenceTarget = [];\n\n                // partition segment into measures\n\n                let position_measure = (node) => {\n                    return Math.floor(node.model.note.beat_start/4)\n                };\n\n                let note_partitions: TreeModel.Node<Note>[][] = _.groupBy(notes_segment_next, position_measure);\n\n                // for (let partition of note_partitions) {\n                //     // get the middle note of the measure\n                //     notes_grouped.push([partition[partition.length/2]])\n                // }\n\n                for (let key_partition of Object.keys(note_partitions)) {\n                    let partition = note_partitions[key_partition];\n                    notes_grouped.push([partition[partition.length/2]])\n                }\n\n                // let logger = new Logger('max');\n                // logger.log(JSON.stringify(notes_segment_next));\n                //\n                // logger.log('done');\n\n                return notes_grouped\n\n            } else {\n                throw ['texture mode', user_input_handler.mode_texture, 'not supported'].join(' ')\n            }\n        }\n\n        postprocess_subtarget(note_subtarget) {\n            note_subtarget.model.note.muted = 1;\n            return note_subtarget;\n        }\n\n        // TODO: verify that we don't have to do anythiing here\n        initialize_render(\n            window: window.MatrixWindow,\n            segments: segment.Segment[],\n            notes_target_track: TreeModel.Node<note.Note>[],\n            struct_train: StructTrain\n        ) {\n            return window\n        }\n\n        // NB: we only have to initialize clips in the target track\n        initialize_tracks(\n            segments: segment.Segment[],\n            track_target: track.Track,\n            track_user_input: track.Track,\n            struct_train: StructTrain\n        ) {\n\n            let matrix_targets = struct_train;\n\n            let logger = new Logger('max');\n\n            for (let i_segment in segments) {\n\n                // let segment = segments[Number(i_segment)];\n\n                let clip = Track.get_clip_at_index(\n                    track_target.get_index(),\n                    Number(i_segment),\n                    track_target.track_dao.messenger\n                );\n\n                let targeted_notes_in_segment = matrix_targets[0][Number(i_segment)].get_notes();\n\n                // logger.log(JSON.stringify(targeted_notes_in_segment));\n\n                // TODO: this won't work for polyphony\n                for (let note of targeted_notes_in_segment) {\n\n                    clip.set_path_deferlow('clip_target');\n\n                    clip.remove_notes(\n                        note.model.note.beat_start,\n                        0,\n                        note.model.note.get_beat_end(),\n                        128\n                    );\n\n                    let note_muted = note;\n\n                    note_muted.model.note.muted = 1;\n\n                    clip.set_notes(\n                        [note_muted]\n                    )\n                }\n            }\n        }\n    }\n}"]}